{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price prediction model of AIRBNB dataset\n",
    "\n",
    "Airbnb is an online marketplace for arranging or offering homestays, or tourism experiences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/muska/Desktop/Data warehousing Project/AB_NYC_2019.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive analysis of the data \n",
    "\n",
    "Descriptive, which answers the question, “What happened?\n",
    "It is used to summarize and explore the behavior of the data involved in the study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = df.columns\n",
    "print(\"All the columns in the DataFrame:\")\n",
    "for column in all_columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the variable types \n",
    "These are divided into two types:\n",
    "\n",
    "1.Numeric data - Continous data ,Discrete data\n",
    "\n",
    "2.Categorical data - Ordinal data ,Nominal data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Categorical Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the CATEGORICAL DATA columns\")\n",
    "print(\"----------------------------------------\")\n",
    "unique_neighbourhood_group = df['neighbourhood_group'].unique()\n",
    "print(\"1.Neighbourhood groups:\")\n",
    "for group in unique_neighbourhood_group:\n",
    "    print(group)\n",
    "unique_neighbourhood = df['neighbourhood'].unique()\n",
    "unique_room_type = df['room_type'].unique()\n",
    "print(\"----------------------------------------\")\n",
    "# Print the unique values in a representative way\n",
    "print(\"2.Neighbourhoods:\")\n",
    "for neighborhood in unique_neighbourhood:\n",
    "    print(neighborhood)\n",
    "print(\"----------------------------------------\")\n",
    "print(\"3.Room types:\")\n",
    "for room_type in unique_room_type:\n",
    "    print(room_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "# Separating discrete and continuous numerical columns\n",
    "discrete_numerical_cols = ['minimum_nights', 'calculated_host_listings_count', 'price']\n",
    "continuous_numerical_cols = [col for col in numerical_cols if col not in discrete_numerical_cols]\n",
    "\n",
    "print(\"This is the NUMERICAL DATA columns\")\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Discrete Numerical Data:\")\n",
    "for column in discrete_numerical_cols:\n",
    "    unique_values = df[column].unique()\n",
    "    unique_values_str = ', '.join(map(str, unique_values))\n",
    "    print(f\"{column} = {unique_values_str}\")\n",
    "\n",
    "    print(\"----------------------------------------\")\n",
    "\n",
    "# Print continuous numerical columns\n",
    "print(\"Continuous Numerical Data:\")\n",
    "for column in continuous_numerical_cols:\n",
    "    if column == 'longitude':\n",
    "        min_value = df[column].min()\n",
    "        max_value = df[column].max()\n",
    "        print(f\"{column}: Min = {min_value}, Max = {max_value}\")\n",
    "    elif column == 'latitude':\n",
    "        min_value = df[column].min()\n",
    "        max_value = df[column].max()\n",
    "        print(f\"{column}: Min = {min_value}, Max = {max_value}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Frequency Distribution`\n",
    "The frequency distribution is an arrangement of values that one or more variables take in a sample. Each entry in the table contains the frequency or count of occurrences of values within a specific group or range, and so the table summarizes the distribution of the sample values.\n",
    "\n",
    "The technique used to create the Percent column uses the following formula:\n",
    "\n",
    "p -> Percent\n",
    "\n",
    "Freq_x -> Frequency of an element x\n",
    "\n",
    "Total freq-> Sum of all frequencies\n",
    "\n",
    "p=100* freq_x/total freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_area = df['neighbourhood_group'].value_counts().reset_index()\n",
    "freq_area.columns = ['neighbourhood_group', 'Frequency']\n",
    "freq_area['Percent'] = (freq_area['Frequency'] / len(df)) * 100\n",
    "\n",
    "# Sort the DataFrame by 'Frequency'\n",
    "freq_area = freq_area.sort_values(by='Frequency')\n",
    "\n",
    "# Reset the index\n",
    "freq_area = freq_area.reset_index(drop=True)\n",
    "print(freq_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_area = df['neighbourhood'].value_counts().reset_index()\n",
    "freq_area.columns = ['neighbourhood', 'Frequency']\n",
    "freq_area['Percent'] = (freq_area['Frequency'] / len(df)) * 100\n",
    "\n",
    "# Sort the DataFrame by 'Frequency'\n",
    "freq_area = freq_area.sort_values(by='Frequency')\n",
    "\n",
    "# Reset the index\n",
    "freq_area = freq_area.reset_index(drop=True)\n",
    "\n",
    "print(freq_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "room_type = df['room_type'].value_counts().reset_index()\n",
    "room_type.columns = ['room_type', 'Frequency']\n",
    "room_type['Percent'] = (room_type['Frequency'] / len(df)) * 100\n",
    "\n",
    "# Sort the DataFrame by 'Frequency'\n",
    "room_type = room_type.sort_values(by='Frequency')\n",
    "\n",
    "# Reset the index\n",
    "room_type = room_type.reset_index(drop=True)\n",
    "\n",
    "print(room_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### CONCLUSION FROM THE FREQUENCY DISTRIBUTION\n",
    "\n",
    "Neighbourhood_group/Location\n",
    "\n",
    "1° Manhattan -> 21661(44.30%)\n",
    "2° Brooklyn -> 20104(41.11%)\n",
    "3° Queens -> 5666(11.58%)\n",
    "\n",
    "neighbourhood/Area\n",
    "\n",
    "1° Williamsburg -> 3920(8.01%)\n",
    "2° Bedford-Stuyvesant -> 3714(7.59%)\n",
    "3° Harlem -> 2658(5.43%)\n",
    "\n",
    "room_type/listing space type\n",
    "\n",
    "1° Entire home/apt -> 25409(51.96%)\n",
    "2° Private room -> 22326(45.66%)\n",
    "3° Shared room -> 1160(2.37%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now we predict and check the effect of different factors on the price predicting the price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Checking Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nulls_summary_table(df):\n",
    "    null_values = pd.DataFrame(df.isnull().sum())\n",
    "    null_values[1] = null_values[0]/len(df)\n",
    "    null_values.columns = ['null_count','null_pct']\n",
    "    return null_values\n",
    "nulls_summary_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Drop the unneccesary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_copy=df\n",
    "df_copy.drop(['name','id','host_name','last_review'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### check the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing all NaN values in 'reviews_per_month' with 0\n",
    "\n",
    "df_copy.fillna({'reviews_per_month':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examing changes \n",
    "# df.reviews_per_month.isnull().sum()\n",
    "df_copy.isnull().sum().sum()  #this is for overall "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Remove the NaN values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.isnull().sum()\n",
    "df_copy.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lets finally check the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.info() \n",
    "# all the values are non null now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Removing where the price is equal to 0 \n",
    "df_copy = df_copy[df_copy['price'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.head()\n",
    "zero_price_count = df_copy[df_copy['price'] == 0].count()['price']\n",
    "print(zero_price_count)  #no value with the price 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Heatmap -> Get Correlation between different variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr =df_copy.corr(method='kendall')\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(corr, annot=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the effect of variables on price (COMPARE THE EFFECT ON THE MODEL BY OTHER VARIABLE AND CHECKING WHICH IS IMP PARAMETER TO DESCRIBE THE MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Neighbourhood Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df_copy, x='neighbourhood_group')\n",
    "plt.title('Neighbourhood Group')\n",
    "\n",
    "# Set the figure size\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(5, 5)\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "print(\"After this we check the relation of the price w.r.t to neighbourhood groups \")\n",
    "\n",
    "median_color = \"red\"\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Create the box plot with custom styling\n",
    "ax = sns.boxplot(data=df, x='neighbourhood_group', y='price',\n",
    "            boxprops={'edgecolor': median_color},  # Highlight the median line\n",
    "            flierprops={'marker': 'o', 'markerfacecolor': 'purple', 'markeredgecolor': 'purple'},  # Add outline curve for skewness\n",
    "            medianprops={'color': median_color, 'linewidth': 2}  # Highlight the median line and make it bold\n",
    "           )\n",
    "plt.title('Price Distribution by Neighbourhood Group')\n",
    "plt.xticks(rotation=45)  # To rotate x-axis labels for better visibility\n",
    "\n",
    "# Highlight the median value with custom text\n",
    "medians = df.groupby(['neighbourhood_group'])['price'].median()\n",
    "for xtick in ax.get_xticks():\n",
    "    ax.text(xtick, medians[xtick], f'{medians[xtick]:.2f}', horizontalalignment='center', color='black', weight='bold')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import branca.colormap as cm\n",
    "\n",
    "# Create a Folium map centered around New York City\n",
    "m = folium.Map(location=[40.7128, -74.0060], zoom_start=11)\n",
    "\n",
    "# Filter the data for the desired price range\n",
    "filtered_price = df[(df['price'] <= 1000) & (df['price'] <= 10000)]\n",
    "\n",
    "# Define a color scale for price\n",
    "price_color_scale = cm.LinearColormap(['green', 'yellow', 'red'], vmin=filtered_price['price'].min(), vmax=filtered_price['price'].max())\n",
    "\n",
    "# Loop through the DataFrame and add data points to the map\n",
    "for index, row in filtered_price.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=5,\n",
    "        color=price_color_scale(row['price']),  # Color based on 'price'\n",
    "        fill=True,\n",
    "        fill_color=price_color_scale(row['price']),  # Fill color based on 'price'\n",
    "        fill_opacity=0.6,\n",
    "        popup=f\"Price: ${row['price']:.2f}<br>Neighborhood: {row['neighbourhood_group']}\",\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add the price color scale to the map\n",
    "price_color_scale.add_to(m)\n",
    "\n",
    "# Display the map inside the Jupyter Notebook\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Room type vs Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df_copy['room_type'], palette=\"plasma\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(5,5)\n",
    "plt.show()\n",
    "\n",
    "print(\"Lets compare the room type effect on the price\")\n",
    "\n",
    "plt.figure(figsize=(15,12))\n",
    "sns.scatterplot(x='room_type', y='price', data=df)\n",
    "\n",
    "plt.xlabel(\"Room Type\", size=13)\n",
    "plt.ylabel(\"Price\", size=13)\n",
    "plt.title(\"Room Type vs Price\",size=15, weight='bold')\n",
    "plt.show()\n",
    "\n",
    "print(\"This shows that the shared room is having less price.Entire room is having the highest followd by private room \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### room type vs price based on neighourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle(\"Room Type vs Price vs Neighbourhood Group\", fontsize=16, fontweight='bold')\n",
    "\n",
    "# Define room types\n",
    "room_types = df_copy['room_type'].unique()\n",
    "\n",
    "# Create a scatter plot for each room type\n",
    "for i, room_type in enumerate(room_types):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    # Filter the data for the specific room type\n",
    "    data_group = df_copy[df_copy['room_type'] == room_type]\n",
    "\n",
    "    sns.scatterplot(x=\"neighbourhood_group\", y=\"price\", hue=\"neighbourhood_group\",\n",
    "                    size=\"neighbourhood_group\", sizes=(50, 200),\n",
    "                    palette=\"Dark2\", data=data_group, ax=ax)\n",
    "\n",
    "    ax.set_title(f\"Room Type: {room_type}\")\n",
    "    ax.set_xlabel(\"Neighbourhood Group\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "\n",
    "# Adjust subplot layout\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### price vs number of reveiw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.set_palette(\"Set1\")\n",
    "\n",
    "sns.lineplot(x='price', y='number_of_reviews', \n",
    "             data=df_copy[df_copy['neighbourhood_group']=='Brooklyn'],\n",
    "             label='Brooklyn')\n",
    "sns.lineplot(x='price', y='number_of_reviews', \n",
    "             data=df_copy[df_copy['neighbourhood_group']=='Manhattan'],\n",
    "             label='Manhattan')\n",
    "sns.lineplot(x='price', y='number_of_reviews', \n",
    "             data=df_copy[df_copy['neighbourhood_group']=='Queens'],\n",
    "             label='Queens')\n",
    "sns.lineplot(x='price', y='number_of_reviews', \n",
    "             data=df_copy[df_copy['neighbourhood_group']=='Staten Island'],\n",
    "             label='Staten Island')\n",
    "sns.lineplot(x='price', y='number_of_reviews', \n",
    "             data=df_copy[df_copy['neighbourhood_group']=='Bronx'],\n",
    "             label='Bronx')\n",
    "plt.xlabel(\"Price\", size=13)\n",
    "plt.ylabel(\"Number of Reviews\", size=13)\n",
    "plt.title(\"Price vs Number of Reviews vs Neighbourhood Group\",size=15, weight='bold')\n",
    "plt.show()\n",
    "\n",
    "# low price high review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### price vs availability_365 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import folium\n",
    "# import pandas as pd\n",
    "# import branca.colormap as cm\n",
    "# # Assuming 'df' is your DataFrame with 'latitude', 'longitude', 'price', and 'availability_365' columns\n",
    "\n",
    "# # Create a Folium map centered around New York City\n",
    "# m = folium.Map(location=[40.7128, -74.0060], zom_start=11)\n",
    "\n",
    "# # Define a custom colormap with a wider range of colors\n",
    "# colors = ['lightblue', 'blue', 'darkblue', 'purple', 'darkred', 'red', 'orange', 'yellow', 'green', 'darkgreen']\n",
    "# price_min = df_copy['price'].min()\n",
    "# price_max = df_copy['price'].max()\n",
    "# colormap = cm.LinearColormap(colors=colors, vmin=price_min, vmax=price_max)\n",
    "\n",
    "# # Loop through the DataFrame and add data points to the map\n",
    "# for index, row in df.iterrows():\n",
    "#     folium.CircleMarker(\n",
    "#         location=[row['latitude'], row['longitude']],\n",
    "#         radius=5,\n",
    "#         color=colormap(row['price']),  # Color based on 'price'\n",
    "#         fill=True,\n",
    "#         fill_color=colormap(row['price']),  # Fill color based on 'price'\n",
    "#         fill_opacity=0.6,\n",
    "#         popup=f\"Price: ${row['price']:.2f}, Availability: {row['availability_365']}\"\n",
    "#     ).add_to(m)\n",
    "\n",
    "# # Add the color legend to the map\n",
    "# colormap.add_to(m)\n",
    "\n",
    "# # Display the map inside the Jupyter Notebook\n",
    "# m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "host listing count affect the price \n",
    "lets go a little but deep inside why we are thinking in this way this is because host listing count means the number of houses owned by that host this seems to be factor not to be considered but if we think a host with more number of property is having more experienced better is the chance that the person is use to his work lets compare the host lisitings count wiht the number of reveiw \n",
    "lets see does more experienced means more price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size if needed\n",
    "plt.scatter(df['calculated_host_listings_count'], df['price'], alpha=0.5)  # Alpha controls point transparency\n",
    "plt.title('Price vs. Host Listing Count')\n",
    "plt.xlabel('Host Listing Count')\n",
    "plt.ylabel('Price')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# no significnat effect shown \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.distplot(df_copy['price'], fit=norm)\n",
    "plt.title(\"Price Distribution Plot\",size=15, weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['price_log'] = np.log(df_copy.price+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.distplot(df_copy['price_log'], fit=norm)\n",
    "plt.title(\"Log-Price Distribution Plot\",size=15, weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop(['host_id','latitude','longitude','neighbourhood','number_of_reviews','reviews_per_month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(7,7))\n",
    "# stats.probplot(df_copy['price_log'], plot=plt)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### checking Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multicollinearity, V=np.linalg.eig(corr)\n",
    "multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encode(df_copy):\n",
    "    for column in df_copy.columns[df_copy.columns.isin(['neighbourhood_group','room_type'])]:\n",
    "        df_copy[column] = df_copy[column].factorize()[0]\n",
    "    return df_copy\n",
    "df_copy_en = Encode(df_copy.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "# Define independent and dependent variables\n",
    "x = df_copy_en.iloc[:, [0, 1, 3, 4, 5]]\n",
    "y = df_copy_en['price_log']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=353)\n",
    "\n",
    "# Display a sample of the training data\n",
    "print(\"Sample of x_train:\")\n",
    "print(x_train.head())\n",
    "print(\"\\nSample of y_train:\")\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a Linear Regression model\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using the Linear Regression model\n",
    "y_pred_linear = reg.predict(x_test)\n",
    "\n",
    "\n",
    "# Calculate and print the R-squared score for Linear Regression\n",
    "linear_regression_r2 = r2_score(y_test, y_pred_linear)\n",
    "print(\"\\nR-squared Score for Linear Regression:\", linear_regression_r2)\n",
    "# Calculate RMSE for Linear Regression\n",
    "linear_rmse = np.sqrt(mean_squared_error(y_test, y_pred_linear))\n",
    "print(\"RMSE for Linear Regression:\", linear_rmse)\n",
    "\n",
    "# Calculate MAE for Linear Regression\n",
    "linear_mae = mean_absolute_error(y_test, y_pred_linear)\n",
    "print(\"MAE for Linear Regression:\", linear_mae)\n",
    "\n",
    "\n",
    "# Create a DataFrame to display actual vs predicted values\n",
    "comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_linear})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets for Decision Tree Regression\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=105)\n",
    "\n",
    "# Create and train a Decision Tree Regression model\n",
    "DTree = DecisionTreeRegressor(min_samples_leaf=0.0001)\n",
    "DTree.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using the Decision Tree Regression model\n",
    "y_pred_tree = DTree.predict(x_test)\n",
    "\n",
    "# Calculate and print the R-squared score for Decision Tree Regression\n",
    "decision_tree_r2 = r2_score(y_test, y_pred_tree)\n",
    "print(\"\\nR-squared Score for Decision Tree Regression:\", decision_tree_r2)\n",
    "tree_rmse = np.sqrt(mean_squared_error(y_test, y_pred_tree))\n",
    "print(\"RMSE for Decision Tree Regression:\", tree_rmse)\n",
    "\n",
    "# Calculate MAE for Decision Tree Regression\n",
    "tree_mae = mean_absolute_error(y_test, y_pred_tree)\n",
    "print(\"MAE for Decision Tree Regression:\", tree_mae)\n",
    "\n",
    "# Create a DataFrame to display actual vs predicted values\n",
    "comparison_df_tree = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_tree})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(comparison_df_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a Lasso Regression model\n",
    "lasso = Lasso()\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using the Lasso Regression model\n",
    "y_pred_lasso = lasso.predict(x_test)\n",
    "\n",
    "# Calculate and print the R-squared score for Lasso Regression\n",
    "lasso_r2 = r2_score(y_test, y_pred_lasso)\n",
    "print(\"\\nR-squared Score for Lasso Regression:\", lasso_r2)\n",
    "\n",
    "lasso_rmse = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "print(\"RMSE for Lasso Regression:\", lasso_rmse)\n",
    "\n",
    "# Calculate MAE for Lasso Regression\n",
    "lasso_mae = mean_absolute_error(y_test, y_pred_lasso)\n",
    "print(\"MAE for Lasso Regression:\", lasso_mae)\n",
    "\n",
    "# Create a DataFrame to display actual vs predicted values\n",
    "comparison_df_tree = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_lasso})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(comparison_df_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a Ridge Regression model\n",
    "ridge = Ridge()\n",
    "ridge.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using the Ridge Regression model\n",
    "y_pred_ridge = ridge.predict(x_test)\n",
    "\n",
    "# Calculate and print the R-squared score for Ridge Regression\n",
    "ridge_r2 = r2_score(y_test, y_pred_ridge)\n",
    "print(\"\\nR-squared Score for Ridge Regression:\", ridge_r2)\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "print(\"RMSE for Ridge Regression:\", ridge_rmse)\n",
    "# Calculate MAE\n",
    "ridge_mae = mean_absolute_error(y_test, y_pred_ridge)\n",
    "print(\"MAE for Ridge Regression:\", ridge_mae)\n",
    "\n",
    "# Create a DataFrame to display actual vs predicted values\n",
    "comparison_df_tree = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_ridge})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(comparison_df_tree)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The MAE value of 0 indicates no error on the model. In other words, there is a perfect prediction. \n",
    "\n",
    "RMSE gives an idea of how much error the system typically makes in its predictions. \n",
    "\n",
    "R2 represents the proportion of the variance for a dependent variable that's explained by an independent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.scatter(df['price_log'],df['neighbourhood'])\n",
    "plt.xlabel(\"CGPA\")\n",
    "plt.ylabel(\"package(in lpa)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "606.4px",
    "left": "31px",
    "top": "110.525px",
    "width": "201.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
